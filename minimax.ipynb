{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "source": [
    "# Ćwiczenie 3\n",
    "\n",
    "Celem ćwiczenia jest imlementacja metody [Minimax z obcinaniem alpha-beta](https://en.wikipedia.org/wiki/Alpha%E2%80%93beta_pruning) do gry Connect Four (czwórki).\n",
    "\n",
    "W trakcie ćwiczenia można skorzystać z reposytorium z implementacją gry [Connect Four udostępnionym przez Jakuba Łyskawę](https://github.com/lychanl/two-player-games). Ewentualnie, można zaimplementować samemu grę Connect Four (ale, tak aby rozwiązanie miało ten sam interfejs co podany poniżej).\n",
    "\n",
    "Implementację Minimax należy przetestować używając różną głębokość przeszukiwania. Implementacja Solvera musi zapewniać interfejs jak poniżej, ale można dodać dowolne metody prywatne oraz klasy wspomagające (jeżeli będą potrzebne).\n",
    "\n",
    "Punktacja:\n",
    "- Działająca metoda Minimax - **2 pkt**\n",
    "- Działająca metoda Minimax z obcinaniem alpha-beta - **1.5 pkt**\n",
    "- Analiza jakości solvera w zależności od głębokości przeszukiwania **1.5pkt**\n",
    "    - należy zaimplementować w tym celu prostą wizualizację rozgrywki dwóch agentów, bądź kilka przykładów 'z ręki'\n",
    "- Jakość kodu **2pkt**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "source": [
    "Aby importowanie elementów z poniższej komórki działało należy umieścić tego notebooka w tym samym folderze co paczkę `two_player_games`:\n",
    "```\n",
    "├── LICENSE\n",
    "├── README.md\n",
    "├── minimax.ipynb # <<< HERE\n",
    "├── test\n",
    "│   ├── __init__.py\n",
    "│   ├── test_connect_four.py\n",
    "│   ├── test_dots_and_boxes.py\n",
    "│   └── test_pick.py\n",
    "└── two_player_games\n",
    "    ├── __init__.py\n",
    "    ├── games\n",
    "    │   ├── connect_four.py\n",
    "    │   └── dots_and_boxes.py\n",
    "    ├── move.py\n",
    "    ├── player.py\n",
    "    └── state.py\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Tuple, List\n",
    "from copy import deepcopy\n",
    "import random\n",
    "    \n",
    "from two_player_games.player import Player\n",
    "from two_player_games.games.connect_four import (\n",
    "    ConnectFour,\n",
    "    ConnectFourMove,\n",
    "    ConnectFourState\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "ROW_COUNT = 6\n",
    "COLUMN_COUNT = 7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "POINTS_MAP = {\n",
    "    \"player_4\": 10000,\n",
    "    \"opponent_4\": -1000,\n",
    "    \"player_2\": 1,\n",
    "    \"opponent_2\": -1,\n",
    "    \"player_3\": 10,\n",
    "    \"opponent_3\": -100,\n",
    "}\n",
    "DEPTH = 1\n",
    "WINDOW_LEN = 4\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "class MinMaxSolver:\n",
    "\n",
    "    def __init__(self, game: ConnectFour):\n",
    "        self.game = game\n",
    "\n",
    "    def evaluate_position(self, player: Player)->float:\n",
    "        points = 0\n",
    "\n",
    "        # vertical\n",
    "        windows_in_col = ROW_COUNT - 3\n",
    "        for col in range(COLUMN_COUNT):\n",
    "            for i in range(windows_in_col):\n",
    "                window = [self.game.state.fields[col][i + k] for k in range(WINDOW_LEN)]\n",
    "                points += self.evaluate_window(window, player)\n",
    "        # horizontal\n",
    "        windows_count_row = COLUMN_COUNT - 3\n",
    "        for row in range(ROW_COUNT):\n",
    "            for i in range(windows_count_row):\n",
    "                window = [self.game.state.fields[i + k][row] for k in range(WINDOW_LEN)]\n",
    "                points += self.evaluate_window(window, player)\n",
    "\n",
    "        # diagonal\n",
    "        for row in range(ROW_COUNT - 3):\n",
    "            for col in range(COLUMN_COUNT - 3):\n",
    "                window = [\n",
    "                    self.game.state.fields[col + i][row + i] for i in range(WINDOW_LEN)\n",
    "                ]\n",
    "                points += self.evaluate_window(window, player)\n",
    "                window = [\n",
    "                    self.game.state.fields[col + 3 - i][row + i]\n",
    "                    for i in range(WINDOW_LEN)\n",
    "                ]\n",
    "                points += self.evaluate_window(window, player)\n",
    "\n",
    "        return points\n",
    "\n",
    "    def evaluate_window(self, window: List, player):\n",
    "        player_count = window.count(player)\n",
    "        other_player_count = len([el for el in window if (el != player and el != None)])\n",
    "        none_count = window.count(None)\n",
    "\n",
    "        if player_count == 4:\n",
    "            return POINTS_MAP[\"player_4\"]\n",
    "        if other_player_count == 4:\n",
    "            return POINTS_MAP[\"opponent_4\"]\n",
    "        if player_count == 2 and none_count == 2:\n",
    "            return POINTS_MAP[\"player_2\"]\n",
    "        if other_player_count == 2 and none_count == 2:\n",
    "            return POINTS_MAP[\"opponent_2\"]\n",
    "        if player_count == 3 and none_count == 1:\n",
    "            return POINTS_MAP[\"player_3\"]\n",
    "        if other_player_count == 3 and none_count == 1:\n",
    "            return POINTS_MAP[\"opponent_3\"]\n",
    "        return 0\n",
    "\n",
    "\n",
    "    def get_best_move(self)->int:\n",
    "        best_score = -float(\"inf\")\n",
    "        best_move = None\n",
    "        for col in range(COLUMN_COUNT):\n",
    "            if not self.is_valid_move(col):\n",
    "                continue\n",
    "            current_state = deepcopy(self.game.state)\n",
    "            self.game.make_move(ConnectFourMove(col))\n",
    "            _, new_score = self.minimax(self.depth, -float(\"inf\"), float(\"inf\"), False)\n",
    "            self.game.state = current_state\n",
    "            if new_score > best_score:\n",
    "                best_move = col\n",
    "                best_score = new_score\n",
    "        return best_move  \n",
    "\n",
    "    def is_valid_move(self, col_index:int)->bool:\n",
    "        return self.game.state.fields[col_index][ROW_COUNT - 1] == None\n",
    "\n",
    "    \n",
    "    def minimax(self, depth, alpha:float, beta:float, is_maximizing_player:bool)-> Tuple[int, float]:\n",
    "        \"\"\"Returns column index and score\"\"\"\n",
    "\n",
    "        if depth == 0 or self.game.state.is_finished():\n",
    "            score = self.evaluate_position(self.game.state.get_current_player())\n",
    "            return (None, score)\n",
    "\n",
    "        if is_maximizing_player:\n",
    "            value = -float(\"inf\")\n",
    "            best_move = None\n",
    "            for col in range(COLUMN_COUNT):\n",
    "                if not self.is_valid_move(col):\n",
    "                    continue\n",
    "                current_state = deepcopy(self.game.state)\n",
    "                self.game.make_move(ConnectFourMove(col))\n",
    "                _, new_score = self.minimax(depth - 1, alpha, beta, False)\n",
    "                self.game.state = current_state\n",
    "                if value < new_score:\n",
    "                    best_move = col\n",
    "                    value = new_score\n",
    "                alpha = max(alpha, value)\n",
    "                if alpha >= beta:\n",
    "                    break\n",
    "            return (best_move, value)\n",
    "        else:\n",
    "            value = float(\"inf\")\n",
    "            best_move = None\n",
    "            for col in range(COLUMN_COUNT):\n",
    "                if not self.is_valid_move(col):\n",
    "                    continue\n",
    "                current_state = deepcopy(self.game.state)\n",
    "                self.game.make_move(ConnectFourMove(col))\n",
    "                _, new_score = self.minimax(depth - 1, alpha, beta, True)\n",
    "                self.game.state = current_state\n",
    "                if value > new_score:\n",
    "                    best_move = col\n",
    "                    value = new_score\n",
    "                beta = min(beta, value)\n",
    "                if beta <= alpha:\n",
    "                    break\n",
    "            return (best_move, value)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Helper functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def play(depth):\n",
    "    \"\"\" Playing from console with  minimax \"\"\"\n",
    "    p1 = Player(\"a\")\n",
    "    p2 = Player(\"b\")\n",
    "    game = ConnectFour(\n",
    "        size=(COLUMN_COUNT, ROW_COUNT), first_player=p1, second_player=p2\n",
    "    )\n",
    "    minimax = MinMaxSolver(game)\n",
    "    minimax.depth = depth\n",
    "    print(game)\n",
    "    while not game.state.is_finished():\n",
    "        move = int(input(\"Enter move: \"))\n",
    "        game.make_move(ConnectFourMove(move))\n",
    "        print(game)\n",
    "\n",
    "        if game.state.is_finished():\n",
    "            print(\"Game is finished\")\n",
    "            print(\"Winner: \" + game.state.get_winner().char)\n",
    "            break\n",
    "\n",
    "        best_move = minimax.get_best_move()\n",
    "        game.make_move(ConnectFourMove(best_move))\n",
    "        print(game)\n",
    "\n",
    "        if game.state.is_finished():\n",
    "            print(\"Winner: \" + game.state.get_winner().char)\n",
    "            break\n",
    "\n",
    "\n",
    "def minimax_with_random_player(depth, print_game=False):\n",
    "    p1 = Player(\"a\")\n",
    "    p2 = Player(\"b\")\n",
    "    if print_game:\n",
    "        print(\"AI player: a\")\n",
    "    game = ConnectFour(\n",
    "        size=(COLUMN_COUNT, ROW_COUNT), first_player=p1, second_player=p2\n",
    "    )\n",
    "    minimax = MinMaxSolver(game)\n",
    "    minimax.depth = depth\n",
    "\n",
    "    while not game.state.is_finished():\n",
    "        for player in [\"ai\", \"random\"]:\n",
    "            if player == \"ai\":\n",
    "                best_move = minimax.get_best_move()\n",
    "                game.make_move(ConnectFourMove(best_move))\n",
    "\n",
    "            else:\n",
    "                move = random.randint(0, COLUMN_COUNT - 1)\n",
    "                game.make_move(ConnectFourMove(move))\n",
    "            if print_game:\n",
    "                print(game)\n",
    "            if game.state.is_finished():\n",
    "                return game.state.get_winner()\n",
    "\n",
    "\n",
    "def check_finish(game, winners):\n",
    "    if game.state.is_finished():\n",
    "        winner = game.state.get_winner()\n",
    "        if not winner:\n",
    "            winners.append(None)\n",
    "        else:\n",
    "            winners.append(winner.char)\n",
    "        return True\n",
    "    return False\n",
    "\n",
    "\n",
    "def one_game_demo(depth):\n",
    "    \"\"\" One game between minimax and random player \"\"\"\n",
    "    print(f\"DEPTH = {depth}\")\n",
    "    winner = minimax_with_random_player(depth=depth, print_game=True)\n",
    "    if winner:\n",
    "        print(f\"winner: {winner.char}\")\n",
    "    else:\n",
    "        print(\"no winner\")\n",
    "\n",
    "\n",
    "def series_of_games_demo(depth_list, no_iterations):\n",
    "    \"\"\" Run series of gaes between random player and minimax\"\"\"\n",
    "    print(f\"Games number : {no_iterations}\")\n",
    "    for depth in depth_list:\n",
    "        print(f\"depth: {depth}\")\n",
    "        winners = []\n",
    "        for _ in range(no_iterations):\n",
    "            winner = minimax_with_random_player(depth=depth)\n",
    "            if not winner:\n",
    "                winners.append(None)\n",
    "            else:\n",
    "                winners.append(winner.char)\n",
    "        random_win_count, ai_win_count = (winners.count(\"b\"), winners.count(\"a\"))\n",
    "        print(f\"random win count: {random_win_count}\")\n",
    "        print(f\"ai win count : {ai_win_count}\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "source": [
    "## Rozgrywka"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Seria gier dla różnych głębokości"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Games number : 100\n",
      "depth: 1\n",
      "random win count: 11\n",
      "ai win count : 89\n",
      "depth: 2\n",
      "random win count: 26\n",
      "ai win count : 74\n",
      "depth: 3\n",
      "random win count: 6\n",
      "ai win count : 93\n"
     ]
    }
   ],
   "source": [
    "depths = [1, 2, 3]\n",
    "no_iterations = 100\n",
    "series_of_games_demo(depths, no_iterations)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Games number : 50\n",
      "depth: 4\n",
      "random win count: 9\n",
      "ai win count : 41\n",
      "depth: 5\n",
      "random win count: 0\n",
      "ai win count : 49\n"
     ]
    }
   ],
   "source": [
    "depths = [4, 5]\n",
    "no_iterations = 50\n",
    "series_of_games_demo(depths, no_iterations)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Wyniki:\n",
    "\n",
    "| Depth      | minimax vs random player|\n",
    "| ----------- | ----------- |\n",
    "| 1        | 89 %       |\n",
    "| 2          | 74 %        |\n",
    "| 3         | 93 %        |\n",
    "| 4         | 82 %        |\n",
    "| 5         | 98 %        |\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Przykładowa rozgrywka"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DEPTH = 4\n",
      "AI player: a\n",
      "Current player: b\n",
      "[ ][ ][ ][ ][ ][ ][ ]\n",
      "[ ][ ][ ][ ][ ][ ][ ]\n",
      "[ ][ ][ ][ ][ ][ ][ ]\n",
      "[ ][ ][ ][ ][ ][ ][ ]\n",
      "[ ][ ][ ][ ][ ][ ][ ]\n",
      "[a][ ][ ][ ][ ][ ][ ]\n",
      "Current player: a\n",
      "[ ][ ][ ][ ][ ][ ][ ]\n",
      "[ ][ ][ ][ ][ ][ ][ ]\n",
      "[ ][ ][ ][ ][ ][ ][ ]\n",
      "[ ][ ][ ][ ][ ][ ][ ]\n",
      "[ ][ ][ ][ ][ ][ ][ ]\n",
      "[a][ ][ ][ ][ ][b][ ]\n",
      "Current player: b\n",
      "[ ][ ][ ][ ][ ][ ][ ]\n",
      "[ ][ ][ ][ ][ ][ ][ ]\n",
      "[ ][ ][ ][ ][ ][ ][ ]\n",
      "[ ][ ][ ][ ][ ][ ][ ]\n",
      "[a][ ][ ][ ][ ][ ][ ]\n",
      "[a][ ][ ][ ][ ][b][ ]\n",
      "Current player: a\n",
      "[ ][ ][ ][ ][ ][ ][ ]\n",
      "[ ][ ][ ][ ][ ][ ][ ]\n",
      "[ ][ ][ ][ ][ ][ ][ ]\n",
      "[b][ ][ ][ ][ ][ ][ ]\n",
      "[a][ ][ ][ ][ ][ ][ ]\n",
      "[a][ ][ ][ ][ ][b][ ]\n",
      "Current player: b\n",
      "[ ][ ][ ][ ][ ][ ][ ]\n",
      "[ ][ ][ ][ ][ ][ ][ ]\n",
      "[a][ ][ ][ ][ ][ ][ ]\n",
      "[b][ ][ ][ ][ ][ ][ ]\n",
      "[a][ ][ ][ ][ ][ ][ ]\n",
      "[a][ ][ ][ ][ ][b][ ]\n",
      "Current player: a\n",
      "[ ][ ][ ][ ][ ][ ][ ]\n",
      "[ ][ ][ ][ ][ ][ ][ ]\n",
      "[a][ ][ ][ ][ ][ ][ ]\n",
      "[b][ ][ ][ ][ ][ ][ ]\n",
      "[a][ ][ ][ ][ ][ ][ ]\n",
      "[a][b][ ][ ][ ][b][ ]\n",
      "Current player: b\n",
      "[ ][ ][ ][ ][ ][ ][ ]\n",
      "[a][ ][ ][ ][ ][ ][ ]\n",
      "[a][ ][ ][ ][ ][ ][ ]\n",
      "[b][ ][ ][ ][ ][ ][ ]\n",
      "[a][ ][ ][ ][ ][ ][ ]\n",
      "[a][b][ ][ ][ ][b][ ]\n",
      "Current player: a\n",
      "[ ][ ][ ][ ][ ][ ][ ]\n",
      "[a][ ][ ][ ][ ][ ][ ]\n",
      "[a][ ][ ][ ][ ][ ][ ]\n",
      "[b][ ][ ][ ][ ][ ][ ]\n",
      "[a][ ][ ][ ][ ][ ][ ]\n",
      "[a][b][ ][b][ ][b][ ]\n",
      "Current player: b\n",
      "[ ][ ][ ][ ][ ][ ][ ]\n",
      "[a][ ][ ][ ][ ][ ][ ]\n",
      "[a][ ][ ][ ][ ][ ][ ]\n",
      "[b][ ][ ][ ][ ][ ][ ]\n",
      "[a][ ][ ][ ][ ][ ][ ]\n",
      "[a][b][a][b][ ][b][ ]\n",
      "Current player: a\n",
      "[ ][ ][ ][ ][ ][ ][ ]\n",
      "[a][ ][ ][ ][ ][ ][ ]\n",
      "[a][ ][ ][ ][ ][ ][ ]\n",
      "[b][ ][ ][ ][ ][ ][ ]\n",
      "[a][b][ ][ ][ ][ ][ ]\n",
      "[a][b][a][b][ ][b][ ]\n",
      "Current player: b\n",
      "[a][ ][ ][ ][ ][ ][ ]\n",
      "[a][ ][ ][ ][ ][ ][ ]\n",
      "[a][ ][ ][ ][ ][ ][ ]\n",
      "[b][ ][ ][ ][ ][ ][ ]\n",
      "[a][b][ ][ ][ ][ ][ ]\n",
      "[a][b][a][b][ ][b][ ]\n",
      "Current player: a\n",
      "[a][ ][ ][ ][ ][ ][ ]\n",
      "[a][ ][ ][ ][ ][ ][ ]\n",
      "[a][ ][ ][ ][ ][ ][ ]\n",
      "[b][ ][ ][ ][ ][ ][ ]\n",
      "[a][b][ ][b][ ][ ][ ]\n",
      "[a][b][a][b][ ][b][ ]\n",
      "Current player: b\n",
      "[a][ ][ ][ ][ ][ ][ ]\n",
      "[a][ ][ ][ ][ ][ ][ ]\n",
      "[a][ ][ ][ ][ ][ ][ ]\n",
      "[b][a][ ][ ][ ][ ][ ]\n",
      "[a][b][ ][b][ ][ ][ ]\n",
      "[a][b][a][b][ ][b][ ]\n",
      "Current player: a\n",
      "[a][ ][ ][ ][ ][ ][ ]\n",
      "[a][ ][ ][ ][ ][ ][ ]\n",
      "[a][ ][ ][ ][ ][ ][ ]\n",
      "[b][a][ ][ ][ ][ ][ ]\n",
      "[a][b][b][b][ ][ ][ ]\n",
      "[a][b][a][b][ ][b][ ]\n",
      "Current player: b\n",
      "[a][ ][ ][ ][ ][ ][ ]\n",
      "[a][ ][ ][ ][ ][ ][ ]\n",
      "[a][ ][ ][ ][ ][ ][ ]\n",
      "[b][a][ ][ ][ ][ ][ ]\n",
      "[a][b][b][b][ ][ ][ ]\n",
      "[a][b][a][b][ ][b][a]\n",
      "Current player: a\n",
      "[a][ ][ ][ ][ ][ ][ ]\n",
      "[a][ ][ ][ ][ ][ ][ ]\n",
      "[a][ ][ ][ ][ ][ ][ ]\n",
      "[b][a][b][ ][ ][ ][ ]\n",
      "[a][b][b][b][ ][ ][ ]\n",
      "[a][b][a][b][ ][b][a]\n",
      "Current player: b\n",
      "[a][ ][ ][ ][ ][ ][ ]\n",
      "[a][ ][ ][ ][ ][ ][ ]\n",
      "[a][a][ ][ ][ ][ ][ ]\n",
      "[b][a][b][ ][ ][ ][ ]\n",
      "[a][b][b][b][ ][ ][ ]\n",
      "[a][b][a][b][ ][b][a]\n",
      "Current player: a\n",
      "[a][ ][ ][ ][ ][ ][ ]\n",
      "[a][ ][ ][ ][ ][ ][ ]\n",
      "[a][a][ ][ ][ ][ ][ ]\n",
      "[b][a][b][ ][ ][ ][ ]\n",
      "[a][b][b][b][ ][b][ ]\n",
      "[a][b][a][b][ ][b][a]\n",
      "Current player: b\n",
      "[a][ ][ ][ ][ ][ ][ ]\n",
      "[a][ ][ ][ ][ ][ ][ ]\n",
      "[a][a][ ][ ][ ][ ][ ]\n",
      "[b][a][b][a][ ][ ][ ]\n",
      "[a][b][b][b][ ][b][ ]\n",
      "[a][b][a][b][ ][b][a]\n",
      "Current player: a\n",
      "[a][ ][ ][ ][ ][ ][ ]\n",
      "[a][ ][ ][ ][ ][ ][ ]\n",
      "[a][a][b][ ][ ][ ][ ]\n",
      "[b][a][b][a][ ][ ][ ]\n",
      "[a][b][b][b][ ][b][ ]\n",
      "[a][b][a][b][ ][b][a]\n",
      "Current player: b\n",
      "[a][ ][ ][ ][ ][ ][ ]\n",
      "[a][ ][a][ ][ ][ ][ ]\n",
      "[a][a][b][ ][ ][ ][ ]\n",
      "[b][a][b][a][ ][ ][ ]\n",
      "[a][b][b][b][ ][b][ ]\n",
      "[a][b][a][b][ ][b][a]\n",
      "Current player: a\n",
      "[a][ ][ ][ ][ ][ ][ ]\n",
      "[a][ ][a][ ][ ][ ][ ]\n",
      "[a][a][b][b][ ][ ][ ]\n",
      "[b][a][b][a][ ][ ][ ]\n",
      "[a][b][b][b][ ][b][ ]\n",
      "[a][b][a][b][ ][b][a]\n",
      "Current player: b\n",
      "[a][ ][a][ ][ ][ ][ ]\n",
      "[a][ ][a][ ][ ][ ][ ]\n",
      "[a][a][b][b][ ][ ][ ]\n",
      "[b][a][b][a][ ][ ][ ]\n",
      "[a][b][b][b][ ][b][ ]\n",
      "[a][b][a][b][ ][b][a]\n",
      "Current player: a\n",
      "[a][ ][a][ ][ ][ ][ ]\n",
      "[a][ ][a][ ][ ][ ][ ]\n",
      "[a][a][b][b][ ][ ][ ]\n",
      "[b][a][b][a][ ][b][ ]\n",
      "[a][b][b][b][ ][b][ ]\n",
      "[a][b][a][b][ ][b][a]\n",
      "Current player: b\n",
      "[a][ ][a][ ][ ][ ][ ]\n",
      "[a][ ][a][ ][ ][ ][ ]\n",
      "[a][a][b][b][ ][a][ ]\n",
      "[b][a][b][a][ ][b][ ]\n",
      "[a][b][b][b][ ][b][ ]\n",
      "[a][b][a][b][ ][b][a]\n",
      "Current player: a\n",
      "[a][ ][a][ ][ ][ ][ ]\n",
      "[a][ ][a][ ][ ][ ][ ]\n",
      "[a][a][b][b][ ][a][ ]\n",
      "[b][a][b][a][ ][b][ ]\n",
      "[a][b][b][b][ ][b][ ]\n",
      "[a][b][a][b][ ][b][a]\n",
      "Current player: b\n",
      "[a][ ][a][ ][ ][ ][ ]\n",
      "[a][ ][a][ ][ ][a][ ]\n",
      "[a][a][b][b][ ][a][ ]\n",
      "[b][a][b][a][ ][b][ ]\n",
      "[a][b][b][b][ ][b][ ]\n",
      "[a][b][a][b][ ][b][a]\n",
      "Current player: a\n",
      "[a][ ][a][ ][ ][ ][ ]\n",
      "[a][b][a][ ][ ][a][ ]\n",
      "[a][a][b][b][ ][a][ ]\n",
      "[b][a][b][a][ ][b][ ]\n",
      "[a][b][b][b][ ][b][ ]\n",
      "[a][b][a][b][ ][b][a]\n",
      "Current player: b\n",
      "[a][ ][a][ ][ ][a][ ]\n",
      "[a][b][a][ ][ ][a][ ]\n",
      "[a][a][b][b][ ][a][ ]\n",
      "[b][a][b][a][ ][b][ ]\n",
      "[a][b][b][b][ ][b][ ]\n",
      "[a][b][a][b][ ][b][a]\n",
      "Current player: a\n",
      "[a][ ][a][ ][ ][a][ ]\n",
      "[a][b][a][ ][ ][a][ ]\n",
      "[a][a][b][b][ ][a][ ]\n",
      "[b][a][b][a][ ][b][ ]\n",
      "[a][b][b][b][ ][b][ ]\n",
      "[a][b][a][b][ ][b][a]\n",
      "Current player: b\n",
      "[a][ ][a][ ][ ][a][ ]\n",
      "[a][b][a][ ][ ][a][ ]\n",
      "[a][a][b][b][ ][a][ ]\n",
      "[b][a][b][a][ ][b][ ]\n",
      "[a][b][b][b][ ][b][a]\n",
      "[a][b][a][b][ ][b][a]\n",
      "Current player: a\n",
      "[a][ ][a][ ][ ][a][ ]\n",
      "[a][b][a][ ][ ][a][ ]\n",
      "[a][a][b][b][ ][a][ ]\n",
      "[b][a][b][a][ ][b][ ]\n",
      "[a][b][b][b][ ][b][a]\n",
      "[a][b][a][b][ ][b][a]\n",
      "Current player: b\n",
      "[a][a][a][ ][ ][a][ ]\n",
      "[a][b][a][ ][ ][a][ ]\n",
      "[a][a][b][b][ ][a][ ]\n",
      "[b][a][b][a][ ][b][ ]\n",
      "[a][b][b][b][ ][b][a]\n",
      "[a][b][a][b][ ][b][a]\n",
      "Current player: a\n",
      "[a][a][a][ ][ ][a][ ]\n",
      "[a][b][a][ ][ ][a][ ]\n",
      "[a][a][b][b][ ][a][ ]\n",
      "[b][a][b][a][ ][b][ ]\n",
      "[a][b][b][b][ ][b][a]\n",
      "[a][b][a][b][ ][b][a]\n",
      "Current player: b\n",
      "[a][a][a][ ][ ][a][ ]\n",
      "[a][b][a][a][ ][a][ ]\n",
      "[a][a][b][b][ ][a][ ]\n",
      "[b][a][b][a][ ][b][ ]\n",
      "[a][b][b][b][ ][b][a]\n",
      "[a][b][a][b][ ][b][a]\n",
      "Current player: a\n",
      "[a][a][a][ ][ ][a][ ]\n",
      "[a][b][a][a][ ][a][ ]\n",
      "[a][a][b][b][ ][a][ ]\n",
      "[b][a][b][a][ ][b][ ]\n",
      "[a][b][b][b][ ][b][a]\n",
      "[a][b][a][b][ ][b][a]\n",
      "Current player: b\n",
      "[a][a][a][ ][ ][a][ ]\n",
      "[a][b][a][a][ ][a][ ]\n",
      "[a][a][b][b][ ][a][ ]\n",
      "[b][a][b][a][ ][b][a]\n",
      "[a][b][b][b][ ][b][a]\n",
      "[a][b][a][b][ ][b][a]\n",
      "Current player: a\n",
      "[a][a][a][ ][ ][a][ ]\n",
      "[a][b][a][a][ ][a][ ]\n",
      "[a][a][b][b][ ][a][ ]\n",
      "[b][a][b][a][ ][b][a]\n",
      "[a][b][b][b][ ][b][a]\n",
      "[a][b][a][b][ ][b][a]\n",
      "Current player: b\n",
      "[a][a][a][ ][ ][a][ ]\n",
      "[a][b][a][a][ ][a][ ]\n",
      "[a][a][b][b][ ][a][a]\n",
      "[b][a][b][a][ ][b][a]\n",
      "[a][b][b][b][ ][b][a]\n",
      "[a][b][a][b][ ][b][a]\n",
      "winner: a\n"
     ]
    }
   ],
   "source": [
    "depth = 4\n",
    "one_game_demo(depth)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Gra z użytkownikiem"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "depth = 4\n",
    "play(depth)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Wnioski\n",
    "\n",
    "### Parametry heurystyki \n",
    "Duże znaczenie na działanie algorytmu ma dobranie heurystki oceny stanu gry. Kiepska heurystyka powoduje, że algorytm nie potrafi popawnie ocenić stanu gry. Ocena stanu gry pozwala algorytmowi minimax wybrać najlepszy ruch. \n",
    "\n",
    "### Głębokość\n",
    "\n",
    "Skuteczność algorytmu minimax w głównej mierze zależy od głębokości przeszukiwania. Głębokość znacznie zwieksza jednak czas wykonywania obliczeń. Im większa głębokość tym lepsze wyniki algorytmu.\n",
    "\n",
    "### Alpha-beta pruning\n",
    "Ucinanie gałęzi za pomocą parametrów alpha i beta znacznie przyspiesza wykonywanie algorytmu."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  },
  "nteract": {
   "version": "nteract-front-end@1.0.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
